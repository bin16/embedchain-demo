llm:
  provider: ollama
  config:
    model: 'deepseek-r1:latest'
    # model: 'llama3.2:latest'
    temperature: 0.5
    top_p: 1
    stream: true
    base_url: 'http://localhost:11434'

embedder:
  provider: ollama
  config:
    model: 'nomic-embed-text:latest'
